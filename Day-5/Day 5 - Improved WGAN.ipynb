{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mb_size = 32\n",
    "X_dim = 784\n",
    "z_dim = 10\n",
    "h_dim = 128\n",
    "lam = 10\n",
    "n_disc = 5\n",
    "lr = 1e-4\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "def sample_z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "\n",
    "def G(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "    return G_prob\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(X, D_W1) + D_b1)\n",
    "    out = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([h_dim, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; D loss: -0.6011; G_loss: 1.845\n",
      "Iter: 1000; D loss: -3.585; G_loss: 0.2246\n",
      "Iter: 2000; D loss: -2.473; G_loss: -0.5106\n",
      "Iter: 3000; D loss: -2.021; G_loss: -0.6321\n",
      "Iter: 4000; D loss: -1.947; G_loss: -0.7018\n",
      "Iter: 5000; D loss: -2.162; G_loss: -0.6881\n",
      "Iter: 6000; D loss: -1.93; G_loss: -0.878\n",
      "Iter: 7000; D loss: -1.714; G_loss: -1.021\n",
      "Iter: 8000; D loss: -1.491; G_loss: -1.011\n",
      "Iter: 9000; D loss: -1.824; G_loss: -0.5309\n",
      "Iter: 10000; D loss: -1.625; G_loss: 0.02787\n",
      "Iter: 11000; D loss: -2.115; G_loss: -0.007266\n",
      "Iter: 12000; D loss: -1.906; G_loss: 0.2681\n",
      "Iter: 13000; D loss: -2.032; G_loss: 0.1682\n",
      "Iter: 14000; D loss: -1.858; G_loss: 0.2463\n",
      "Iter: 15000; D loss: -2.12; G_loss: 0.712\n",
      "Iter: 16000; D loss: -1.772; G_loss: 1.103\n",
      "Iter: 17000; D loss: -1.801; G_loss: 1.138\n",
      "Iter: 18000; D loss: -1.846; G_loss: 1.253\n",
      "Iter: 19000; D loss: -1.736; G_loss: 1.537\n",
      "Iter: 20000; D loss: -1.965; G_loss: 1.139\n",
      "Iter: 21000; D loss: -1.694; G_loss: 1.138\n",
      "Iter: 22000; D loss: -1.611; G_loss: 1.138\n",
      "Iter: 23000; D loss: -1.96; G_loss: 1.016\n",
      "Iter: 24000; D loss: -1.612; G_loss: 0.9007\n",
      "Iter: 25000; D loss: -1.713; G_loss: 0.8505\n",
      "Iter: 26000; D loss: -1.879; G_loss: 0.6025\n",
      "Iter: 27000; D loss: -1.852; G_loss: 0.6223\n",
      "Iter: 28000; D loss: -1.447; G_loss: 0.8575\n",
      "Iter: 29000; D loss: -1.599; G_loss: 0.9174\n",
      "Iter: 30000; D loss: -1.54; G_loss: 0.7872\n",
      "Iter: 31000; D loss: -1.734; G_loss: 0.867\n",
      "Iter: 32000; D loss: -1.627; G_loss: 0.6659\n",
      "Iter: 33000; D loss: -1.553; G_loss: 0.6284\n",
      "Iter: 34000; D loss: -1.402; G_loss: 0.7977\n",
      "Iter: 35000; D loss: -1.885; G_loss: 0.6708\n",
      "Iter: 36000; D loss: -1.453; G_loss: 0.6135\n",
      "Iter: 37000; D loss: -1.426; G_loss: 0.8569\n",
      "Iter: 38000; D loss: -1.611; G_loss: 0.7071\n",
      "Iter: 39000; D loss: -1.372; G_loss: 1.149\n",
      "Iter: 40000; D loss: -1.485; G_loss: 0.8734\n",
      "Iter: 41000; D loss: -1.583; G_loss: 0.8168\n",
      "Iter: 42000; D loss: -1.396; G_loss: 0.9639\n",
      "Iter: 43000; D loss: -1.408; G_loss: 1.164\n",
      "Iter: 44000; D loss: -1.494; G_loss: 1.07\n",
      "Iter: 45000; D loss: -1.204; G_loss: 0.8967\n",
      "Iter: 46000; D loss: -1.543; G_loss: 0.9528\n",
      "Iter: 47000; D loss: -1.407; G_loss: 1.171\n",
      "Iter: 48000; D loss: -1.278; G_loss: 1.391\n",
      "Iter: 49000; D loss: -1.413; G_loss: 1.378\n",
      "Iter: 50000; D loss: -1.447; G_loss: 1.427\n",
      "Iter: 51000; D loss: -0.9824; G_loss: 1.664\n",
      "Iter: 52000; D loss: -1.415; G_loss: 1.78\n",
      "Iter: 53000; D loss: -1.173; G_loss: 1.677\n",
      "Iter: 54000; D loss: -1.363; G_loss: 1.76\n",
      "Iter: 55000; D loss: -1.238; G_loss: 2.143\n",
      "Iter: 56000; D loss: -1.204; G_loss: 2.405\n",
      "Iter: 57000; D loss: -1.35; G_loss: 2.076\n",
      "Iter: 58000; D loss: -1.261; G_loss: 2.407\n",
      "Iter: 59000; D loss: -1.165; G_loss: 2.683\n",
      "Iter: 60000; D loss: -1.138; G_loss: 2.501\n",
      "Iter: 61000; D loss: -1.048; G_loss: 2.766\n",
      "Iter: 62000; D loss: -1.146; G_loss: 3.008\n",
      "Iter: 63000; D loss: -1.28; G_loss: 2.76\n",
      "Iter: 64000; D loss: -1.105; G_loss: 2.886\n",
      "Iter: 65000; D loss: -1.186; G_loss: 3.035\n",
      "Iter: 66000; D loss: -1.208; G_loss: 3.217\n",
      "Iter: 67000; D loss: -1.313; G_loss: 3.639\n",
      "Iter: 68000; D loss: -1.191; G_loss: 3.688\n",
      "Iter: 69000; D loss: -1.198; G_loss: 3.806\n",
      "Iter: 70000; D loss: -1.143; G_loss: 3.892\n",
      "Iter: 71000; D loss: -1.271; G_loss: 3.992\n",
      "Iter: 72000; D loss: -1.217; G_loss: 4.051\n",
      "Iter: 73000; D loss: -1.195; G_loss: 4.373\n",
      "Iter: 74000; D loss: -1.295; G_loss: 4.414\n",
      "Iter: 75000; D loss: -1.249; G_loss: 4.232\n",
      "Iter: 76000; D loss: -1.229; G_loss: 4.615\n",
      "Iter: 77000; D loss: -0.9809; G_loss: 4.666\n",
      "Iter: 78000; D loss: -1.184; G_loss: 4.715\n",
      "Iter: 79000; D loss: -1.132; G_loss: 4.751\n",
      "Iter: 80000; D loss: -1.053; G_loss: 4.756\n",
      "Iter: 81000; D loss: -1.138; G_loss: 4.796\n",
      "Iter: 82000; D loss: -0.9461; G_loss: 5.168\n",
      "Iter: 83000; D loss: -1.199; G_loss: 5.313\n",
      "Iter: 84000; D loss: -1.086; G_loss: 4.975\n",
      "Iter: 85000; D loss: -1.049; G_loss: 5.549\n",
      "Iter: 86000; D loss: -1.064; G_loss: 5.333\n",
      "Iter: 87000; D loss: -1.102; G_loss: 5.684\n",
      "Iter: 88000; D loss: -0.8749; G_loss: 5.747\n",
      "Iter: 89000; D loss: -0.9894; G_loss: 5.317\n",
      "Iter: 90000; D loss: -0.9284; G_loss: 5.517\n",
      "Iter: 91000; D loss: -1.202; G_loss: 5.935\n",
      "Iter: 92000; D loss: -1.069; G_loss: 6.097\n",
      "Iter: 93000; D loss: -0.8208; G_loss: 5.743\n",
      "Iter: 94000; D loss: -0.9797; G_loss: 5.971\n",
      "Iter: 95000; D loss: -0.9967; G_loss: 6.041\n",
      "Iter: 96000; D loss: -1.146; G_loss: 5.855\n",
      "Iter: 97000; D loss: -1.081; G_loss: 6.033\n",
      "Iter: 98000; D loss: -0.8814; G_loss: 6.128\n",
      "Iter: 99000; D loss: -1.147; G_loss: 6.083\n",
      "Iter: 100000; D loss: -1.024; G_loss: 5.799\n",
      "Iter: 101000; D loss: -1.07; G_loss: 5.957\n",
      "Iter: 102000; D loss: -1.053; G_loss: 6.168\n",
      "Iter: 103000; D loss: -1.008; G_loss: 5.643\n",
      "Iter: 104000; D loss: -0.8373; G_loss: 5.684\n",
      "Iter: 105000; D loss: -1.186; G_loss: 5.959\n",
      "Iter: 106000; D loss: -0.9388; G_loss: 6.011\n",
      "Iter: 107000; D loss: -0.9174; G_loss: 6.188\n",
      "Iter: 108000; D loss: -0.999; G_loss: 6.145\n",
      "Iter: 109000; D loss: -0.9946; G_loss: 6.126\n",
      "Iter: 110000; D loss: -1.136; G_loss: 5.805\n",
      "Iter: 111000; D loss: -1.106; G_loss: 6.192\n",
      "Iter: 112000; D loss: -1.176; G_loss: 6.143\n",
      "Iter: 113000; D loss: -0.8196; G_loss: 6.082\n",
      "Iter: 114000; D loss: -0.9846; G_loss: 6.171\n",
      "Iter: 115000; D loss: -0.9536; G_loss: 6.344\n",
      "Iter: 116000; D loss: -0.8409; G_loss: 6.186\n",
      "Iter: 117000; D loss: -1.017; G_loss: 6.09\n",
      "Iter: 118000; D loss: -1.126; G_loss: 6.284\n",
      "Iter: 119000; D loss: -0.7407; G_loss: 6.176\n",
      "Iter: 120000; D loss: -0.8828; G_loss: 6.228\n",
      "Iter: 121000; D loss: -1.015; G_loss: 6.327\n",
      "Iter: 122000; D loss: -0.9876; G_loss: 6.039\n",
      "Iter: 123000; D loss: -1.114; G_loss: 6.237\n",
      "Iter: 124000; D loss: -0.8153; G_loss: 6.247\n",
      "Iter: 125000; D loss: -1.065; G_loss: 6.006\n",
      "Iter: 126000; D loss: -0.8938; G_loss: 6.213\n",
      "Iter: 127000; D loss: -0.8591; G_loss: 6.389\n",
      "Iter: 128000; D loss: -1.164; G_loss: 5.929\n",
      "Iter: 129000; D loss: -0.9798; G_loss: 6.067\n",
      "Iter: 130000; D loss: -0.8287; G_loss: 6.326\n",
      "Iter: 131000; D loss: -1.204; G_loss: 6.26\n",
      "Iter: 132000; D loss: -0.99; G_loss: 6.6\n",
      "Iter: 133000; D loss: -0.8907; G_loss: 6.293\n",
      "Iter: 134000; D loss: -0.8803; G_loss: 6.204\n",
      "Iter: 135000; D loss: -1.073; G_loss: 6.425\n",
      "Iter: 136000; D loss: -0.9312; G_loss: 6.471\n",
      "Iter: 137000; D loss: -1.036; G_loss: 6.178\n",
      "Iter: 138000; D loss: -0.9347; G_loss: 6.399\n",
      "Iter: 139000; D loss: -0.853; G_loss: 6.222\n",
      "Iter: 140000; D loss: -0.8986; G_loss: 6.347\n",
      "Iter: 141000; D loss: -0.9283; G_loss: 6.644\n",
      "Iter: 142000; D loss: -1.03; G_loss: 6.601\n",
      "Iter: 143000; D loss: -1.054; G_loss: 6.804\n",
      "Iter: 144000; D loss: -0.9095; G_loss: 6.352\n",
      "Iter: 145000; D loss: -1.173; G_loss: 6.394\n",
      "Iter: 146000; D loss: -0.9469; G_loss: 6.955\n",
      "Iter: 147000; D loss: -0.9542; G_loss: 6.833\n",
      "Iter: 148000; D loss: -1.145; G_loss: 6.603\n",
      "Iter: 149000; D loss: -0.9462; G_loss: 6.692\n",
      "Iter: 150000; D loss: -0.8863; G_loss: 6.585\n",
      "Iter: 151000; D loss: -1.038; G_loss: 6.625\n",
      "Iter: 152000; D loss: -0.8572; G_loss: 6.485\n",
      "Iter: 153000; D loss: -0.9311; G_loss: 6.379\n",
      "Iter: 154000; D loss: -0.8706; G_loss: 6.661\n",
      "Iter: 155000; D loss: -1.015; G_loss: 6.428\n",
      "Iter: 156000; D loss: -1.013; G_loss: 6.605\n",
      "Iter: 157000; D loss: -0.9033; G_loss: 6.664\n",
      "Iter: 158000; D loss: -1.145; G_loss: 6.585\n",
      "Iter: 159000; D loss: -1.009; G_loss: 6.615\n",
      "Iter: 160000; D loss: -0.8654; G_loss: 6.337\n",
      "Iter: 161000; D loss: -0.7495; G_loss: 6.395\n",
      "Iter: 162000; D loss: -0.9256; G_loss: 6.687\n",
      "Iter: 163000; D loss: -1.151; G_loss: 6.575\n",
      "Iter: 164000; D loss: -1.032; G_loss: 6.351\n",
      "Iter: 165000; D loss: -0.9429; G_loss: 6.856\n",
      "Iter: 166000; D loss: -0.9423; G_loss: 6.787\n",
      "Iter: 167000; D loss: -0.5953; G_loss: 6.548\n",
      "Iter: 168000; D loss: -0.9857; G_loss: 6.633\n",
      "Iter: 169000; D loss: -0.9855; G_loss: 6.379\n",
      "Iter: 170000; D loss: -0.9196; G_loss: 6.519\n",
      "Iter: 171000; D loss: -0.5594; G_loss: 6.719\n",
      "Iter: 172000; D loss: -0.7672; G_loss: 7.061\n",
      "Iter: 173000; D loss: -1.121; G_loss: 6.672\n",
      "Iter: 174000; D loss: -0.8592; G_loss: 6.718\n",
      "Iter: 175000; D loss: -0.8947; G_loss: 6.654\n",
      "Iter: 176000; D loss: -0.8349; G_loss: 6.484\n",
      "Iter: 177000; D loss: -0.7435; G_loss: 6.64\n",
      "Iter: 178000; D loss: -1.083; G_loss: 6.916\n",
      "Iter: 179000; D loss: -0.7186; G_loss: 7.244\n",
      "Iter: 180000; D loss: -1.038; G_loss: 6.633\n",
      "Iter: 181000; D loss: -0.9251; G_loss: 6.454\n"
     ]
    }
   ],
   "source": [
    "G_sample = G(z)\n",
    "D_real = D(X)\n",
    "D_fake = D(G_sample)\n",
    "\n",
    "eps = tf.random_uniform([mb_size, 1], minval=0., maxval=1.)\n",
    "X_inter = eps*X + (1. - eps)*G_sample\n",
    "grad = tf.gradients(D(X_inter), [X_inter])[0]\n",
    "grad_norm = tf.sqrt(tf.reduce_sum((grad)**2, axis=1))\n",
    "grad_pen = lam * tf.reduce_mean((grad_norm - 1)**2)\n",
    "\n",
    "D_loss = tf.reduce_mean(D_fake) - tf.reduce_mean(D_real) + grad_pen\n",
    "G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "D_solver = (tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5)\n",
    "            .minimize(D_loss, var_list=theta_D))\n",
    "G_solver = (tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5)\n",
    "            .minimize(G_loss, var_list=theta_G))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    for it in range(1000000):\n",
    "        for _ in range(n_disc):\n",
    "            X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "            _, D_loss_curr = sess.run(\n",
    "                [D_solver, D_loss],\n",
    "                feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}\n",
    "            )\n",
    "\n",
    "        _, G_loss_curr = sess.run(\n",
    "            [G_solver, G_loss],\n",
    "            feed_dict={z: sample_z(mb_size, z_dim)}\n",
    "        )\n",
    "\n",
    "        if it % 1000 == 0:\n",
    "            print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'\n",
    "                  .format(it, D_loss_curr, G_loss_curr))\n",
    "\n",
    "            if it % 1000 == 0:\n",
    "                samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})\n",
    "\n",
    "                fig = plot(samples)\n",
    "                plt.savefig('out/{}.png'\n",
    "                            .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "                i += 1\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
